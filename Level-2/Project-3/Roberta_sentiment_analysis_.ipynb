{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "c7035401630046e18b2b693accea3455",
      "47347cd48e1142f6a7b42ad2358f0ebf",
      "c4f33d8898754c538fd96c3c473a41c8",
      "3cd56cc5c1a74aa3ac931c3a5e4fdd9b",
      "cf327c2c2add4e9aa2c8ceed4113abfd",
      "b825882bb4364b80be02fcbd584f457b",
      "ae009c82346a48f899e8b627a1c2989f",
      "b01507c5046d4115af4e9edd3eeb6fc1",
      "4d8194c170ed4e9c9bdbd4e6250aa461",
      "b7408c6b13bd44c09d1b00b3141ea1e6",
      "fda4633f3a0044fa9333ed2bbcd774a2",
      "d46a7beeab97460d81dd538ded17cfdc",
      "f042f4ef121d49c08affc5be20baff7a",
      "89758dbe94964a96bce179af7ce722d4",
      "3581dddb46304c2d819f27b0f9733040",
      "d779d681a733476888247701dd15a3af",
      "25af7594abcf454db11e5682557c465d",
      "522cd617f8364dd2931b14a40b46cb88",
      "bf7d22fbee19436db250acbd38f4a195",
      "5fec1b323b9e4532a46977890148bc4c",
      "06aba7efc264465e80fdc746bf90773e",
      "0b8665e5cc7f44bab4c030d1cf59189e",
      "232989eb65294dd9b514f11101a2cdf7",
      "8f0ab0630c794622874aaa0a73fef5da",
      "3fad92eb182447228566c57851cb9f84",
      "1d6b441843e64cdba37bf33238d4beb3",
      "a0f6e7d42b784aecb20adf1eab2e65fd",
      "cde9b05c164f4a9ea64f2eb23e4e19f8",
      "0fdf2ae5250e4b95ab781bd9bbc4c603",
      "73561f0a825c415e98d78586873c75fa",
      "f4c7cda65b224190be4fb3285e6896d8",
      "4c0e81a5b4fc499e8bb62452586ae1a7",
      "9b6a1c12a036471b82302db07ed71e8a",
      "4890cb2aca5247ae94a24c3c4d224003",
      "1b377d12dc7340c7a04cef2b24800ef3",
      "f0f7d3f3ad9041bca2ce93201d445c44",
      "53b86f7b2de441b7a44eff0a486aa0ac",
      "beeb71605c954d929ab0e1e3eeeb04a6",
      "7e1fa6ebe3f048f9bdd7e88999a4fdbc",
      "ae3f1b7da5da48f59624411f83dcb8ef",
      "db96e4c802b9425b9861f4e6deb3e876",
      "d3ffd6a000764cc2a6425bd315225f22",
      "73db05bd661f479c92e3d7c20099cdbc",
      "036893f642b24a75b17ff516f8674a91",
      "adc85f4fef5144c6abd4b2d379120a8c",
      "50d301757a744b0b8405401cebb5fbe1",
      "20da013383d545de9a4dc8c69f3a023d",
      "c0942897836b4a219664fd9fcedfae8d",
      "feb7750f85774dfba96359edcd46abdb",
      "2b61905e13b1407ea34cc33175e08e97",
      "9435a30723c14c338adb39f64ea72731",
      "9e946268e68647af8e743f6f4ad15b92",
      "fde5e602e33f49278a96c7c4b97882f2",
      "b659aef32377447ca43ba703073c8082",
      "13250f1e8b7c45df85ab5e8907610b09",
      "fcfc0b94665b40f8bcf6db976363e151",
      "ab5c6e9556d140fa8f24d3426d826d4a",
      "4ac3df2882bf4a5a906d8512296c132b",
      "4ad5a09d73ae4275b1594c11e70655a8",
      "7afe28c25a3841bf8fb4c692b3b6a574",
      "1b52ccb1b82c41da9e84c3ca507131ea",
      "64c4412c06914977b2495b550929e67c",
      "618c2e0510f84bdbb8a7edcbc69dae72",
      "9e60422471ad41f6a4965a90baf0fe7b",
      "f2e95bcb503148b299d6021159af2058",
      "2813e09b3f954a0982882e086f7d7890"
     ]
    },
    "executionInfo": {
     "elapsed": 30983,
     "status": "ok",
     "timestamp": 1753101323641,
     "user": {
      "displayName": "Raiyan",
      "userId": "01393611700209861732"
     },
     "user_tz": -330
    },
    "id": "xR9xieT8Kjfq",
    "outputId": "f7e4bf14-758c-40ab-e894-c7a5a626d68c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7035401630046e18b2b693accea3455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46a7beeab97460d81dd538ded17cfdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232989eb65294dd9b514f11101a2cdf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4890cb2aca5247ae94a24c3c4d224003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc85f4fef5144c6abd4b2d379120a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcfc0b94665b40f8bcf6db976363e151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#roberta based tweet sentiment analysis\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76889,
     "status": "ok",
     "timestamp": 1753095227008,
     "user": {
      "displayName": "Raiyan",
      "userId": "01393611700209861732"
     },
     "user_tz": -330
    },
    "id": "KtFHldeGRXke",
    "outputId": "5b90709e-1a26-48b1-e413-7a252123dca7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        textID                                               text  \\\n",
      "0       textID                                               text   \n",
      "1       textID                                               text   \n",
      "2   cb774db0d1                I`d have responded, if I were going   \n",
      "3   549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
      "4   088c60f138                          my boss is bullying me...   \n",
      "5   9642c003ef                     what interview! leave me alone   \n",
      "6   358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
      "7   28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
      "8   6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
      "9   50e14c0bb8                                         Soooo high   \n",
      "10  e050245fbd                                        Both of you   \n",
      "11  fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n",
      "12  2339a9b08b   as much as i love to be hopeful, i reckon the...   \n",
      "13  16fab9f95b  I really really like the song Love Story by Ta...   \n",
      "14  74a76f6e0a       My Sharpie is running DANGERously low on ink   \n",
      "15  04dd1d2e34  i want to go to music tonight but i lost my vo...   \n",
      "16  bbe3cbf620                         test test from the LG enV2   \n",
      "17  8a939bfb59                              Uh oh, I am sunburned   \n",
      "18  3440297f8b   S`ok, trying to plot alternatives as we speak...   \n",
      "19  919fa93391  i`ve been sick for the past few days  and thus...   \n",
      "20  af3fed7fc3         is back home now      gonna miss every one   \n",
      "21  40e7becabf                         Hes just not that into you   \n",
      "22  04d17ef61e   oh Marly, I`m so sorry!!  I hope you find her...   \n",
      "23  e48b0b8a23  Playing Ghost Online is really interesting. Th...   \n",
      "24  7de057cf40  is cleaning the house for her family who is co...   \n",
      "25  9ce5570064  gotta restart my computer .. I thought Win7 wa...   \n",
      "26  0c8cc71c46  SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...   \n",
      "27  e00c6ef376  the free fillin` app on my ipod is fun, im add...   \n",
      "28  852edc3769                                         I`m sorry.   \n",
      "29  bdc32ea43c  On the way to Malaysia...no internet access to...   \n",
      "\n",
      "    roberta_neg  roberta_neu  roberta_pos  \n",
      "0      0.254576     0.511313     0.234111  \n",
      "1      0.254576     0.511313     0.234111  \n",
      "2      0.064939     0.808318     0.126744  \n",
      "3      0.918158     0.066100     0.015742  \n",
      "4      0.924613     0.070741     0.004646  \n",
      "5      0.783082     0.192980     0.023938  \n",
      "6      0.564197     0.404575     0.031229  \n",
      "7      0.116091     0.404589     0.479320  \n",
      "8      0.001926     0.027040     0.971034  \n",
      "9      0.063866     0.503986     0.432148  \n",
      "10     0.175853     0.710262     0.113885  \n",
      "11     0.001742     0.025501     0.972757  \n",
      "12     0.546504     0.351814     0.101682  \n",
      "13     0.001145     0.016146     0.982709  \n",
      "14     0.905131     0.086659     0.008210  \n",
      "15     0.609226     0.335675     0.055099  \n",
      "16     0.052875     0.890180     0.056945  \n",
      "17     0.745060     0.226186     0.028755  \n",
      "18     0.362765     0.594603     0.042631  \n",
      "19     0.923157     0.069149     0.007694  \n",
      "20     0.657471     0.279625     0.062903  \n",
      "21     0.619499     0.358545     0.021956  \n",
      "22     0.333122     0.465860     0.201018  \n",
      "23     0.001647     0.014093     0.984260  \n",
      "24     0.036250     0.842734     0.121016  \n",
      "25     0.576908     0.367698     0.055395  \n",
      "26     0.341493     0.587060     0.071447  \n",
      "27     0.002154     0.012737     0.985108  \n",
      "28     0.615627     0.338319     0.046054  \n",
      "29     0.568334     0.395422     0.036244  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "df1 = pd.read_csv(\"twitter_data_500.csv\", header=None)\n",
    "df1.columns = ['textID', 'text']\n",
    "def polarity_scores_roberta(texts):\n",
    "    neg = []\n",
    "    neu = []\n",
    "    pos = []\n",
    "    for text in texts:\n",
    "        if not isinstance(text, str) or text.strip() == \"\":\n",
    "            neg.append(0)\n",
    "            neu.append(0)\n",
    "            pos.append(0)\n",
    "            continue\n",
    "        encoded = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded)\n",
    "        scores = output.logits[0].numpy()\n",
    "        scores = softmax(scores)\n",
    "        neg.append(scores[0])\n",
    "        neu.append(scores[1])\n",
    "        pos.append(scores[2])\n",
    "    return neg, neu, pos\n",
    "neg, neu, pos = polarity_scores_roberta(df1[\"text\"].tolist())\n",
    "df1['roberta_neg'] = neg\n",
    "df1['roberta_neu'] = neu\n",
    "df1['roberta_pos'] = pos\n",
    "# Display results\n",
    "print(df1.head(30))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOZH2U7C/RjDRbUYD3A+hdz",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
